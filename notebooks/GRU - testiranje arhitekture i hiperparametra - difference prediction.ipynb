{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db05d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, RNN, LSTM, GRU, SpatialDropout1D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebe99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e741663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d678cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\mata2\\Desktop\\master\\podaci\\0k\\X\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cd7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4ae0b",
   "metadata": {},
   "source": [
    "Napravljen je pandas DataFrame gde su atributi zasebno pokrenute putanje, dok ce ciljna promenljiva da bude srednja vrednost svih putanja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88795fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = []\n",
    "for file in dir:\n",
    "    file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60d37a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3da659f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files_names = file_names[:int(percent_train*len(file_names))]\n",
    "test_file_names = file_names[int(percent_train*len(file_names))::]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41f6085",
   "metadata": {},
   "source": [
    "Ide do 15 trening skup, posle do 15-20 validacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2da1dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kord_sum = [0 for x in range(61000)]\n",
    "\n",
    "for file in train_files_names[:15]:\n",
    "    current_file = pd.read_csv(path+'/'+file, header=None)[:61000].astype('int')\n",
    "\n",
    "    for i in range(len(current_file)):\n",
    "        kord_sum[i] += current_file[0][i]\n",
    "average_kord_train = [x//len(train_files_names[:15]) for x in kord_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6c073",
   "metadata": {},
   "source": [
    "kord za validacioni skup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a55eb4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kord_sum = [0 for x in range(61000)]\n",
    "\n",
    "for file in train_files_names[15:20]:\n",
    "    current_file = pd.read_csv(path+'/'+file, header=None)[:61000].astype('int')\n",
    "\n",
    "    for i in range(len(current_file)):\n",
    "        kord_sum[i] += current_file[0][i]\n",
    "average_kord_test = [x//len(train_files_names[15:20]) for x in kord_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5deef469",
   "metadata": {},
   "outputs": [],
   "source": [
    "train__ = np.concatenate([pd.read_csv(path + \"/\" + file, header=None)[:61000].astype('int')\n",
    "                              for file in train_files_names], axis=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d67e3e29",
   "metadata": {},
   "source": [
    "test_ = np.concatenate([pd.read_csv(path + \"/\" + file, header=None)[:61000].astype('int')\n",
    "                              for file in test_file_names], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce1ea16",
   "metadata": {},
   "source": [
    "Test skup je od 15 fajlova, dok je validacioni od 5\n",
    "Validacioni skup = test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d11f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = train__[61000*15::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1d3497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train__[:61000*15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11191964",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(int(len(train_)/61000)):\n",
    "    exec(f\"razlika_trening_{j} = []\")\n",
    "    for i in range(61000):\n",
    "        exec(f\"razlika_trening_{j}.append(average_kord_train[i] - train_[j*61000+i])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8786872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(int(len(test_)/61000)):\n",
    "    exec(f\"razlika_test_{j} = []\")\n",
    "    for i in range(61000):\n",
    "        exec(f\"razlika_test_{j}.append(average_kord_test[i] - train_[j*61000+i])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea029876",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_podaci = []\n",
    "for j in range(int(len(train_)/61000)):\n",
    "    for i in range(61000):\n",
    "        exec(f'train_podaci.append(razlika_trening_{j}[i][0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "744c182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_podaci = []\n",
    "for j in range(int(len(test_)/61000)):\n",
    "    for i in range(61000):\n",
    "        exec(f'test_podaci.append(razlika_test_{j}[i][0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22c0faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries_split(data, time_steps):\n",
    "\n",
    "  # Get the number of samples in the data\n",
    "  num_samples = len(data) - time_steps\n",
    "\n",
    "  # Create empty arrays to store features and target values\n",
    "  x_train = np.zeros((num_samples, time_steps, 1))\n",
    "  y_train = np.zeros((num_samples, 1))\n",
    "\n",
    "  # Loop through the data and create features and target values\n",
    "  for i in range(num_samples):\n",
    "    # Extract a slice of data for the current feature\n",
    "    x_train[i] = data[i:i+time_steps, :]\n",
    "\n",
    "    # The target value is the next value after the feature\n",
    "    y_train[i] = data[i+time_steps, 0]\n",
    "\n",
    "  return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7eacd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_podaci = np.asarray(train_podaci).reshape(-1,1)\n",
    "test_podaci = np.asarray(test_podaci).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7aeaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17c88e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = create_timeseries_split(train_podaci, time_steps)\n",
    "test_X, test_y = create_timeseries_split(test_podaci, time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb6fc943",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (time_steps,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "da91b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(7)\n",
    "optimizerMSE = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "modelMSE = Sequential()\n",
    "modelMSE.add(GRU(units = 16, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "#modelMSE.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "modelMSE.compile(loss='mean_squared_error', optimizer = optimizerMSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3be24268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14297/14297 - 35s - loss: 2.0493 - 35s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 33s - loss: 0.9427 - 33s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 33s - loss: 0.9152 - 33s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 33s - loss: 0.9050 - 33s/epoch - 2ms/step\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m historyMSE \u001b[38;5;241m=\u001b[39m modelMSE\u001b[38;5;241m.\u001b[39mfit(train_X, train_y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    869\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    870\u001b[0m   )\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1487\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1488\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1489\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1490\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1491\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1492\u001b[0m   )\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mD:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "historyMSE = modelMSE.fit(train_X, train_y, epochs=10, batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f42f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = modelMSE.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d14edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict_MSE = modelMSE.predict(train_X)\n",
    "test_predict_MSE = modelMSE.predict(test_X)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2915d20",
   "metadata": {},
   "source": [
    "plt.plot(historyMSE.epoch, historyMSE.history['loss'], label='training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20ea69b0",
   "metadata": {},
   "source": [
    "plt.plot(test_predict_MSE,'b')\n",
    "#plt.plot(train_podaci[61000:61000*2])\n",
    "#plt.plot(train_podaci[61000*2:61000*3])\n",
    "plt.plot(train_y[:len(test_predict_MSE)],'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b8efe39",
   "metadata": {},
   "source": [
    "plt.plot(test_predict_MSE,'b')\n",
    "#plt.plot(train_podaci[61000:61000*2])\n",
    "#plt.plot(train_podaci[61000*2:61000*3])\n",
    "plt.plot(train_y[:len(test_predict_MSE)],'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32e213cf",
   "metadata": {},
   "source": [
    "# Plot the result\n",
    "def plot_result(trainY, testY, x_predict, test_predict):\n",
    "    actual = np.append(trainY, testY)\n",
    "    predictions = np.append(x_predict, test_predict)\n",
    "    rows = len(actual)\n",
    "    plt.figure(figsize=(15, 6), dpi=80)\n",
    "    plt.plot(range(rows), actual)\n",
    "    plt.plot(range(rows), predictions)\n",
    "    plt.axvline(x=len(train_y), color='r')\n",
    "    plt.legend(['Actual', 'Predictions'])\n",
    "    plt.title('Actual and Predicted Values. The Red Line Separates The Training And Test Examples')\n",
    "    plt.show()\n",
    "plot_result(train_y, test_y, train_predict_MSE, test_predict_MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42053f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_list = [1,2,4,5,8,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf1540a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Users\\mata2\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "14297/14297 - 22s - loss: 2.5902 - 22s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 19s - loss: 1.7841 - 19s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 19s - loss: 1.7834 - 19s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 19s - loss: 1.7834 - 19s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 19s - loss: 1.7834 - 19s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 19s - loss: 1.7831 - 19s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 19s - loss: 1.7829 - 19s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 19s - loss: 1.7830 - 19s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 19s - loss: 1.7827 - 19s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 19s - loss: 1.7828 - 19s/epoch - 1ms/step\n",
      "9532/9532 [==============================] - 10s 1ms/step - loss: 2.4786\n",
      "best_skor 2.478580951690674 best_step 1\n",
      "Epoch 1/10\n",
      "14297/14297 - 24s - loss: 2.3381 - 24s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 22s - loss: 1.3450 - 22s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 22s - loss: 1.3147 - 22s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 22s - loss: 1.3037 - 22s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 22s - loss: 1.2980 - 22s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 22s - loss: 1.2940 - 22s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 22s - loss: 1.2910 - 22s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 22s - loss: 1.2890 - 22s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 22s - loss: 1.2879 - 22s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 22s - loss: 1.2868 - 22s/epoch - 2ms/step\n",
      "9532/9532 [==============================] - 11s 1ms/step - loss: 1.8002\n",
      "best_skor 1.800212025642395 best_step 2\n",
      "Epoch 1/10\n",
      "14297/14297 - 29s - loss: 2.1428 - 29s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 27s - loss: 1.0455 - 27s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 27s - loss: 1.0111 - 27s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 27s - loss: 0.9972 - 27s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 27s - loss: 0.9900 - 27s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 27s - loss: 0.9852 - 27s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 27s - loss: 0.9821 - 27s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 27s - loss: 0.9796 - 27s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 27s - loss: 0.9777 - 27s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 27s - loss: 0.9757 - 27s/epoch - 2ms/step\n",
      "9532/9532 [==============================] - 12s 1ms/step - loss: 1.3645\n",
      "best_skor 1.3644758462905884 best_step 4\n",
      "Epoch 1/10\n",
      "14297/14297 - 32s - loss: 2.0493 - 32s/epoch - 2ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 30s - loss: 0.9427 - 30s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 33s - loss: 0.9152 - 33s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 32s - loss: 0.9050 - 32s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 33s - loss: 0.8991 - 33s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 34s - loss: 0.8951 - 34s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 34s - loss: 0.8921 - 34s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 34s - loss: 0.8898 - 34s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 34s - loss: 0.8876 - 34s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 34s - loss: 0.8859 - 34s/epoch - 2ms/step\n",
      "9532/9532 [==============================] - 14s 1ms/step - loss: 1.2327\n",
      "best_skor 1.2326542139053345 best_step 5\n",
      "Epoch 1/10\n",
      "14297/14297 - 46s - loss: 2.0699 - 46s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 43s - loss: 0.9437 - 43s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 42s - loss: 0.8987 - 42s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 42s - loss: 0.8772 - 42s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 42s - loss: 0.8635 - 42s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 41s - loss: 0.8543 - 41s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 42s - loss: 0.8481 - 42s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 42s - loss: 0.8437 - 42s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 42s - loss: 0.8404 - 42s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 42s - loss: 0.8373 - 42s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 15s 2ms/step - loss: 1.1485\n",
      "best_skor 1.1485064029693604 best_step 8\n",
      "Epoch 1/10\n",
      "14297/14297 - 50s - loss: 2.1682 - 50s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 47s - loss: 0.9518 - 47s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 47s - loss: 0.9129 - 47s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 47s - loss: 0.8897 - 47s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 47s - loss: 0.8756 - 47s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 51s - loss: 0.8650 - 51s/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 50s - loss: 0.8578 - 50s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 48s - loss: 0.8523 - 48s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 48s - loss: 0.8479 - 48s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 49s - loss: 0.8432 - 49s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 17s 2ms/step - loss: 1.1799\n",
      "best_skor 1.1485064029693604\n",
      "best_step 8\n"
     ]
    }
   ],
   "source": [
    "best_step = None\n",
    "best_skor = float('inf')\n",
    "\n",
    "for step in time_steps_list:\n",
    "    train_X, train_y = create_timeseries_split(train_podaci, step)\n",
    "    test_X, test_y = create_timeseries_split(test_podaci, step)\n",
    "    input_shape = (step,1)\n",
    "    \n",
    "    keras.utils.set_random_seed(7)\n",
    "    optimizerMSE = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    modelMSE = Sequential()\n",
    "    modelMSE.add(GRU(units = 16, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "    modelMSE.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "    modelMSE.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "    #modelMSE.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "    modelMSE.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "    modelMSE.compile(loss='mean_squared_error', optimizer = optimizerMSE)\n",
    "    \n",
    "    historyMSE = modelMSE.fit(train_X, train_y, epochs=10, batch_size = 64, verbose = 2)\n",
    "    train_scores = modelMSE.evaluate(test_X, test_y)\n",
    "    \n",
    "    if train_scores < best_skor:\n",
    "        best_skor = train_scores\n",
    "        best_step = step\n",
    "        \n",
    "        print('best_skor', best_skor, 'best_step',best_step)\n",
    "\n",
    "print('best_skor', best_skor)\n",
    "print('best_step', best_step)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d48507b",
   "metadata": {},
   "source": [
    "best steps [8 > 5 >~10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6bd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be3282eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 8\n",
    "input_shape = (time_steps,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d87c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = create_timeseries_split(train_podaci, time_steps)\n",
    "test_X, test_y = create_timeseries_split(test_podaci, time_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a86c9",
   "metadata": {},
   "source": [
    "# TESTIRANJE ARHITEKTURE i LR/BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8662585",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_unit = [8,16]\n",
    "unit1 = [8,16]\n",
    "unit2 = [8,16]\n",
    "LR = [0.01,0.001]\n",
    "batch_size = [32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a33e5a84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28594/28594 - 85s - loss: 1.8519 - 85s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 81s - loss: 0.9701 - 81s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 82s - loss: 0.9329 - 82s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 84s - loss: 0.9182 - 84s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 94s - loss: 0.9075 - 94s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 94s - loss: 0.8990 - 94s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 95s - loss: 0.8920 - 95s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 92s - loss: 0.8857 - 92s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 90s - loss: 0.8807 - 90s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 93s - loss: 0.8761 - 93s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 16s 2ms/step - loss: 1.2181\n",
      "best_skor:  1.218113899230957 best_gru:  8 best_unit1:  8 best_unit2:  8 best batch size:  32\n",
      "Epoch 1/10\n",
      "14297/14297 - 47s - loss: 2.3009 - 47s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 44s - loss: 1.0031 - 44s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 43s - loss: 0.9494 - 43s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 44s - loss: 0.9255 - 44s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 43s - loss: 0.9108 - 43s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 43s - loss: 0.9004 - 43s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 43s - loss: 0.8918 - 43s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 47s - loss: 0.8841 - 47s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 46s - loss: 0.8782 - 46s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 46s - loss: 0.8731 - 46s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 16s 2ms/step - loss: 1.2136\n",
      "best_skor:  1.2135964632034302 best_gru:  8 best_unit1:  8 best_unit2:  8 best batch size:  64\n",
      "Epoch 1/10\n",
      "28594/28594 - 96s - loss: 1.8753 - 96s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 93s - loss: 0.9744 - 93s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 90s - loss: 0.9396 - 90s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 88s - loss: 0.9229 - 88s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 87s - loss: 0.9109 - 87s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 94s - loss: 0.9017 - 94s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 93s - loss: 0.8943 - 93s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 92s - loss: 0.8878 - 92s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 86s - loss: 0.8824 - 86s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 88s - loss: 0.8775 - 88s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 15s 2ms/step - loss: 1.2143\n",
      "Epoch 1/10\n",
      "14297/14297 - 50s - loss: 2.4006 - 50s/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 44s - loss: 1.0436 - 44s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 44s - loss: 0.9653 - 44s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 47s - loss: 0.9413 - 47s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 44s - loss: 0.9277 - 44s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 45s - loss: 0.9169 - 45s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 48s - loss: 0.9074 - 48s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 47s - loss: 0.8999 - 47s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 48s - loss: 0.8934 - 48s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 50s - loss: 0.8882 - 50s/epoch - 4ms/step\n",
      "9531/9531 [==============================] - 17s 2ms/step - loss: 1.2252\n",
      "Epoch 1/10\n",
      "28594/28594 - 92s - loss: 1.7222 - 92s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 92s - loss: 0.9375 - 92s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 89s - loss: 0.9043 - 89s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 96s - loss: 0.8910 - 96s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 91s - loss: 0.8834 - 91s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 91s - loss: 0.8788 - 91s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 91s - loss: 0.8746 - 91s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 88s - loss: 0.8712 - 88s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 91s - loss: 0.8680 - 91s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 91s - loss: 0.8655 - 91s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 20s 2ms/step - loss: 1.2070\n",
      "best_skor:  1.2070080041885376 best_gru:  8 best_unit1:  16 best_unit2:  8 best batch size:  32\n",
      "Epoch 1/10\n",
      "14297/14297 - 49s - loss: 2.2003 - 49s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 46s - loss: 1.0190 - 46s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 47s - loss: 0.9632 - 47s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 46s - loss: 0.9313 - 46s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 47s - loss: 0.9103 - 47s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 46s - loss: 0.8964 - 46s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 45s - loss: 0.8868 - 45s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 45s - loss: 0.8799 - 45s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 44s - loss: 0.8749 - 44s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 45s - loss: 0.8709 - 45s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 16s 2ms/step - loss: 1.2147\n",
      "Epoch 1/10\n",
      "28594/28594 - 86s - loss: 1.7333 - 86s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 75s - loss: 0.9612 - 75s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 71s - loss: 0.9147 - 71s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 71s - loss: 0.8973 - 71s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 73s - loss: 0.8869 - 73s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 72s - loss: 0.8798 - 72s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 71s - loss: 0.8746 - 71s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 71s - loss: 0.8699 - 71s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 71s - loss: 0.8659 - 71s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 71s - loss: 0.8618 - 71s/epoch - 2ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1945\n",
      "best_skor:  1.194538950920105 best_gru:  8 best_unit1:  16 best_unit2:  16 best batch size:  32\n",
      "Epoch 1/10\n",
      "14297/14297 - 39s - loss: 2.1491 - 39s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 36s - loss: 1.0179 - 36s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 36s - loss: 0.9678 - 36s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 36s - loss: 0.9323 - 36s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 36s - loss: 0.9081 - 36s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 36s - loss: 0.8935 - 36s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 36s - loss: 0.8833 - 36s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 36s - loss: 0.8757 - 36s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 36s - loss: 0.8707 - 36s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 36s - loss: 0.8664 - 36s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.2093\n",
      "Epoch 1/10\n",
      "28594/28594 - 74s - loss: 1.8463 - 74s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 72s - loss: 1.0145 - 72s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 72s - loss: 0.9472 - 72s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 71s - loss: 0.9133 - 71s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 71s - loss: 0.8939 - 71s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 71s - loss: 0.8806 - 71s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 71s - loss: 0.8698 - 71s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 71s - loss: 0.8613 - 71s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 71s - loss: 0.8544 - 71s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 71s - loss: 0.8495 - 71s/epoch - 2ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1746\n",
      "best_skor:  1.1745543479919434 best_gru:  16 best_unit1:  8 best_unit2:  8 best batch size:  32\n",
      "Epoch 1/10\n",
      "14297/14297 - 39s - loss: 2.2398 - 39s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 36s - loss: 1.0707 - 36s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 36s - loss: 0.9842 - 36s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 36s - loss: 0.9399 - 36s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 36s - loss: 0.9135 - 36s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 36s - loss: 0.8961 - 36s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 36s - loss: 0.8841 - 36s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 36s - loss: 0.8752 - 36s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 36s - loss: 0.8684 - 36s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 36s - loss: 0.8629 - 36s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1999\n",
      "Epoch 1/10\n",
      "28594/28594 - 75s - loss: 1.6633 - 75s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 72s - loss: 0.9213 - 72s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 72s - loss: 0.8888 - 72s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 72s - loss: 0.8720 - 72s/epoch - 3ms/step\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28594/28594 - 72s - loss: 0.8605 - 72s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 72s - loss: 0.8533 - 72s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 72s - loss: 0.8470 - 72s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 72s - loss: 0.8423 - 72s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 72s - loss: 0.8389 - 72s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 72s - loss: 0.8355 - 72s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1513\n",
      "best_skor:  1.1513310670852661 best_gru:  16 best_unit1:  8 best_unit2:  16 best batch size:  32\n",
      "Epoch 1/10\n",
      "14297/14297 - 38s - loss: 2.0699 - 38s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 36s - loss: 0.9437 - 36s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 36s - loss: 0.8987 - 36s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 36s - loss: 0.8772 - 36s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 36s - loss: 0.8635 - 36s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 36s - loss: 0.8543 - 36s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 36s - loss: 0.8481 - 36s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 36s - loss: 0.8437 - 36s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 36s - loss: 0.8404 - 36s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 36s - loss: 0.8373 - 36s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1485\n",
      "best_skor:  1.1485064029693604 best_gru:  16 best_unit1:  8 best_unit2:  16 best batch size:  64\n",
      "Epoch 1/10\n",
      "28594/28594 - 75s - loss: 1.6286 - 75s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 73s - loss: 0.9338 - 73s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 73s - loss: 0.8943 - 73s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 73s - loss: 0.8744 - 73s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 73s - loss: 0.8616 - 73s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 73s - loss: 0.8543 - 73s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 73s - loss: 0.8477 - 73s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 73s - loss: 0.8425 - 73s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 73s - loss: 0.8378 - 73s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 73s - loss: 0.8343 - 73s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1600\n",
      "Epoch 1/10\n",
      "14297/14297 - 38s - loss: 1.9745 - 38s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 36s - loss: 0.9655 - 36s/epoch - 2ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 36s - loss: 0.9157 - 36s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 36s - loss: 0.8930 - 36s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 36s - loss: 0.8776 - 36s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 36s - loss: 0.8669 - 36s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 36s - loss: 0.8588 - 36s/epoch - 2ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 36s - loss: 0.8528 - 36s/epoch - 2ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 36s - loss: 0.8486 - 36s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 36s - loss: 0.8444 - 36s/epoch - 2ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1738\n",
      "Epoch 1/10\n",
      "28594/28594 - 75s - loss: 1.6011 - 75s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "28594/28594 - 72s - loss: 0.9462 - 72s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "28594/28594 - 73s - loss: 0.9046 - 73s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "28594/28594 - 72s - loss: 0.8866 - 72s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "28594/28594 - 73s - loss: 0.8739 - 73s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "28594/28594 - 73s - loss: 0.8652 - 73s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "28594/28594 - 72s - loss: 0.8590 - 72s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "28594/28594 - 72s - loss: 0.8541 - 72s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "28594/28594 - 72s - loss: 0.8503 - 72s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "28594/28594 - 73s - loss: 0.8468 - 73s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1806\n",
      "Epoch 1/10\n",
      "14297/14297 - 39s - loss: 1.8804 - 39s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "14297/14297 - 36s - loss: 0.9740 - 36s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "14297/14297 - 36s - loss: 0.9230 - 36s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "14297/14297 - 36s - loss: 0.8961 - 36s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "14297/14297 - 36s - loss: 0.8823 - 36s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "14297/14297 - 38s - loss: 0.8733 - 38s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "14297/14297 - 41s - loss: 0.8659 - 41s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "14297/14297 - 40s - loss: 0.8600 - 40s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "14297/14297 - 40s - loss: 0.8557 - 40s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "14297/14297 - 39s - loss: 0.8519 - 39s/epoch - 3ms/step\n",
      "9531/9531 [==============================] - 13s 1ms/step - loss: 1.1867\n",
      "best_skor:  1.1485064029693604\n",
      "best_gru:  16\n",
      "best_unit1:  8\n",
      "best_unit2:  16\n",
      "best batch size:  64\n"
     ]
    }
   ],
   "source": [
    "best_skor = float('inf')\n",
    "best_gru = None\n",
    "best_unit1 = None\n",
    "best_unit2 = None\n",
    "best_batch = None\n",
    "best_LR = None\n",
    "\n",
    "for gru in gru_unit:\n",
    "    for uni1 in unit1:\n",
    "        for uni2 in unit2:\n",
    "            #for rate in LR:\n",
    "            for batch in batch_size:\n",
    "\n",
    "                keras.utils.set_random_seed(7)\n",
    "                optimizerMSE = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "                model = Sequential()\n",
    "                model.add(GRU(units = gru, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "                model.add(Dense(units = uni1, activation=keras.layers.LeakyReLU()))\n",
    "                model.add(Dense(units = uni2, activation=keras.layers.LeakyReLU()))\n",
    "                model.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "                model.compile(loss='mean_squared_error', optimizer = optimizerMSE)\n",
    "\n",
    "                model.fit(train_X, train_y, epochs = 10, batch_size = batch, verbose = 2)\n",
    "                train_scores = model.evaluate(test_X, test_y)\n",
    "\n",
    "                if train_scores < best_skor:\n",
    "                    best_skor = train_scores\n",
    "                    best_gru = gru\n",
    "                    best_unit1 = uni1\n",
    "                    best_unit2 = uni2\n",
    "#                    best_LR = rate\n",
    "                    best_batch = batch\n",
    "\n",
    "                    print('best_skor: ', best_skor,'best_gru: ', best_gru,'best_unit1: ', best_unit1,'best_unit2: ', best_unit2,'best batch size: ', best_batch)\n",
    "print('best_skor: ', best_skor)                    \n",
    "print('best_gru: ', best_gru)\n",
    "print('best_unit1: ', best_unit1)\n",
    "print('best_unit2: ', best_unit2)\n",
    "#print('best learning rate: ', best_LR)    \n",
    "print('best batch size: ', best_batch)    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94e914a2",
   "metadata": {},
   "source": [
    "MAE:\n",
    "/\n",
    "MSE:\n",
    "best_skor:  1.1485064029693604\n",
    "best_gru:  16\n",
    "best_unit1:  8\n",
    "best_unit2:  16\n",
    "best batch size:  64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9eb6d621",
   "metadata": {},
   "source": [
    "LR = [0.01,0.001,0.0001,0.00001]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "075db969",
   "metadata": {},
   "source": [
    "best_skor_LR = float('inf')\n",
    "best_LR = None\n",
    "\n",
    "for rate in LR:\n",
    "    keras.utils.set_random_seed(7)\n",
    "    optimizerMSE = keras.optimizers.Adam(learning_rate=rate)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = 16, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer = optimizerMSE)\n",
    "    \n",
    "    model.fit(train_X, train_y, epochs=10, batch_size = 64, verbose = 2)\n",
    "    train_scores = model.evaluate(test_X, test_y)\n",
    "    \n",
    "    if train_scores < best_skor_LR:\n",
    "        best_skor_LR = train_scores\n",
    "        best_LR = rate\n",
    "print('best_skor: ', best_skor_LR)\n",
    "print('best learning rate: ', best_LR)    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1e2071e2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "06161cd7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90b495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b696ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3f4c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [64,128,256,512,1024,2048,4096]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79efbd4a",
   "metadata": {},
   "source": [
    "best_skor_batch = float('inf')\n",
    "best_batch = None\n",
    "\n",
    "for batch in batch_size:\n",
    "    optimizerMSE = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    keras.utils.set_random_seed(7)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(units = 16, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "    model.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer = optimizerMSE)\n",
    "    \n",
    "    model.fit(train_X, train_y, epochs=10, batch_size = batch, verbose = 2)\n",
    "    train_scores = model.evaluate(test_X, test_y)\n",
    "    \n",
    "    if train_scores < best_skor_batch:\n",
    "        best_skor_batch = train_scores\n",
    "        best_batch = batch\n",
    "print('best_skor: ', best_skor_batch)\n",
    "print('best batch size: ', best_batch)    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fb408a7",
   "metadata": {},
   "source": [
    "MSE\n",
    "best_skor:  1.1485064029693604\n",
    "best batch size:  64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ceb74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(7)\n",
    "optimizerMSE = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "modelMSE = Sequential()\n",
    "modelMSE.add(GRU(units = 16, input_shape = input_shape, activation = keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 16, activation=keras.layers.LeakyReLU()))\n",
    "#modelMSE.add(Dense(units = 8, activation=keras.layers.LeakyReLU()))\n",
    "modelMSE.add(Dense(units = 1, activation=keras.layers.LeakyReLU(), bias_initializer='zeros', kernel_initializer='normal'))\n",
    "modelMSE.compile(loss='mean_squared_error', optimizer = optimizerMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68b8acb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelMAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m historyMAE \u001b[38;5;241m=\u001b[39m modelMAE\u001b[38;5;241m.\u001b[39mfit(train_X, train_y, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelMAE' is not defined"
     ]
    }
   ],
   "source": [
    "historyMAE = modelMAE.fit(train_X, train_y, epochs=10, batch_size = 16, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8282cb32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "894/894 - 9s - loss: 7173579776.0000 - 9s/epoch - 10ms/step\n",
      "Epoch 2/10\n",
      "894/894 - 2s - loss: 48031884.0000 - 2s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "894/894 - 2s - loss: 1464.7377 - 2s/epoch - 2ms/step\n",
      "Epoch 4/10\n",
      "894/894 - 2s - loss: 1464.3621 - 2s/epoch - 2ms/step\n",
      "Epoch 5/10\n",
      "894/894 - 2s - loss: 1464.1544 - 2s/epoch - 2ms/step\n",
      "Epoch 6/10\n",
      "894/894 - 2s - loss: 1464.0243 - 2s/epoch - 2ms/step\n",
      "Epoch 7/10\n",
      "894/894 - 2s - loss: 1463.9316 - 2s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "894/894 - 2s - loss: 1463.8832 - 2s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "894/894 - 2s - loss: 1463.6785 - 2s/epoch - 2ms/step\n",
      "Epoch 10/10\n",
      "894/894 - 2s - loss: 1463.3251 - 2s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "historyMSE = modelMSE.fit(train_X, train_y, epochs=10, batch_size = 1024, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "454b9424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28594/28594 [==============================] - 37s 1ms/step - loss: 1463.4017\n"
     ]
    }
   ],
   "source": [
    "#train_scores_MAE = modelMAE.evaluate(test_X, test_y)\n",
    "train_scores_MSE = modelMSE.evaluate(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ce84951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28594/28594 [==============================] - 36s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_predict_MSE = modelMSE.predict(test_X)\n",
    "#test_predict_MAE = modelMAE.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f321747b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecc50b1d",
   "metadata": {},
   "source": [
    "# TESTIRANJE SA VISE INSTANCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db00ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
